{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras import layers\n",
    "from keras import models\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.optimizers import Adam\n",
    "import keras.backend as K\n",
    "import librosa\n",
    "import librosa.display\n",
    "import pylab\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import figure\n",
    "import gc\n",
    "from path import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transfer Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I employed transfer learning using imagenet weights on the MFC pictures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras_preprocessing.image import ImageDataGenerator\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "TrainLabels = pd.read_csv(r\"F:\\Data Science - Competitions\\Audio Data Sets\\Urban Sound Classfication\\train\\train.csv\",dtype=str)\n",
    "TestLabels = pd.read_csv(r\"F:\\Data Science - Competitions\\Audio Data Sets\\Urban Sound Classfication\\test\\test.csv\",dtype = str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            ID             Class\n",
      "0        0.jpg             siren\n",
      "1        1.jpg      street_music\n",
      "2        2.jpg          drilling\n",
      "3        3.jpg             siren\n",
      "4        4.jpg          dog_bark\n",
      "5        6.jpg  children_playing\n",
      "6       10.jpg      street_music\n",
      "7       11.jpg          drilling\n",
      "8       12.jpg          gun_shot\n",
      "9       15.jpg          dog_bark\n",
      "10      17.jpg     engine_idling\n",
      "11      18.jpg             siren\n",
      "12      19.jpg          gun_shot\n",
      "13      20.jpg     engine_idling\n",
      "14      22.jpg   air_conditioner\n",
      "15      24.jpg   air_conditioner\n",
      "16      26.jpg     engine_idling\n",
      "17      27.jpg             siren\n",
      "18      32.jpg  children_playing\n",
      "19      33.jpg        jackhammer\n",
      "20      35.jpg          gun_shot\n",
      "21      36.jpg             siren\n",
      "22      37.jpg        jackhammer\n",
      "23      38.jpg      street_music\n",
      "24      40.jpg        jackhammer\n",
      "25      42.jpg     engine_idling\n",
      "26      43.jpg             siren\n",
      "27      44.jpg  children_playing\n",
      "28      45.jpg        jackhammer\n",
      "29      46.jpg     engine_idling\n",
      "...        ...               ...\n",
      "5405  8691.jpg      street_music\n",
      "5406  8693.jpg          car_horn\n",
      "5407  8694.jpg      street_music\n",
      "5408  8695.jpg   air_conditioner\n",
      "5409  8699.jpg      street_music\n",
      "5410  8701.jpg   air_conditioner\n",
      "5411  8703.jpg          gun_shot\n",
      "5412  8704.jpg             siren\n",
      "5413  8705.jpg        jackhammer\n",
      "5414  8706.jpg             siren\n",
      "5415  8707.jpg          gun_shot\n",
      "5416  8709.jpg          dog_bark\n",
      "5417  8710.jpg      street_music\n",
      "5418  8711.jpg          dog_bark\n",
      "5419  8712.jpg        jackhammer\n",
      "5420  8713.jpg          dog_bark\n",
      "5421  8714.jpg     engine_idling\n",
      "5422  8715.jpg             siren\n",
      "5423  8716.jpg  children_playing\n",
      "5424  8717.jpg        jackhammer\n",
      "5425  8720.jpg      street_music\n",
      "5426  8721.jpg     engine_idling\n",
      "5427  8722.jpg          dog_bark\n",
      "5428  8723.jpg      street_music\n",
      "5429  8724.jpg  children_playing\n",
      "5430  8725.jpg     engine_idling\n",
      "5431  8726.jpg          dog_bark\n",
      "5432  8727.jpg     engine_idling\n",
      "5433  8728.jpg     engine_idling\n",
      "5434  8729.jpg   air_conditioner\n",
      "\n",
      "[5435 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "TrainLabels[\"ID\"] = TrainLabels[\"ID\"].apply(lambda x: x+\".jpg\")\n",
    "print(TrainLabels)\n",
    "datagen=ImageDataGenerator(rescale=1./255.,validation_split=0.3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3805 validated image filenames belonging to 10 classes.\n"
     ]
    }
   ],
   "source": [
    "train_generator=datagen.flow_from_dataframe(\n",
    "    dataframe=TrainLabels,\n",
    "    directory=\"working/train/\",\n",
    "    x_col=\"ID\",\n",
    "    y_col=\"Class\",\n",
    "    subset=\"training\",\n",
    "    batch_size=32,\n",
    "    seed=42,\n",
    "    shuffle=True,\n",
    "    class_mode=\"categorical\",\n",
    "    target_size=(64,64))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1630 validated image filenames belonging to 10 classes.\n"
     ]
    }
   ],
   "source": [
    "valid_generator=datagen.flow_from_dataframe(\n",
    "    dataframe=TrainLabels,\n",
    "    directory=\"working/train/\",\n",
    "    x_col=\"ID\",\n",
    "    y_col=\"Class\",\n",
    "    subset=\"validation\",\n",
    "    batch_size=32,\n",
    "    seed=42,\n",
    "    shuffle=True,\n",
    "    class_mode=\"categorical\",\n",
    "    target_size=(64,64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Dense, Activation, Flatten, Dropout, BatchNormalization\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras import regularizers, optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications.vgg16 import decode_predictions\n",
    "from keras.applications.vgg16 import VGG16\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg_imagenet = VGG16(include_top=False, weights='imagenet', input_shape = (64,64,3))\n",
    "for layer in vgg_imagenet.layers:\n",
    "    layer.freeze = True\n",
    "    \n",
    "vgg_imagenet.layers[-1].freeze = False\n",
    "flatten = Flatten()(vgg_imagenet.layers[-1].output)\n",
    "dense = Dense(10,activation='softmax')(flatten)\n",
    "new_model = Model(vgg_imagenet.layers[0].input,dense)\n",
    "new_model.compile(loss=\"categorical_crossentropy\",optimizer = \"Adam\" ,metrics=[\"accuracy\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_3 (InputLayer)         (None, 64, 64, 3)         0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 64, 64, 64)        1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 64, 64, 64)        36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 32, 32, 64)        0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 32, 32, 128)       73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 32, 32, 128)       147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 16, 16, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 16, 16, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 16, 16, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 16, 16, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 8, 8, 256)         0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 8, 8, 512)         1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 8, 8, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 8, 8, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 4, 4, 512)         0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 4, 4, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 4, 4, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 4, 4, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 2, 2, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                20490     \n",
      "=================================================================\n",
      "Total params: 14,735,178\n",
      "Trainable params: 14,735,178\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "new_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "118/118 [==============================] - 380s 3s/step - loss: 1.6827 - acc: 0.3714 - val_loss: 1.6191 - val_acc: 0.4293\n",
      "Epoch 2/10\n",
      "118/118 [==============================] - 389s 3s/step - loss: 1.5175 - acc: 0.4441 - val_loss: 1.5321 - val_acc: 0.4255\n",
      "Epoch 3/10\n",
      "118/118 [==============================] - 384s 3s/step - loss: 1.4298 - acc: 0.4743 - val_loss: 1.3156 - val_acc: 0.5232\n",
      "Epoch 4/10\n",
      "118/118 [==============================] - 387s 3s/step - loss: 1.2669 - acc: 0.5342 - val_loss: 1.2601 - val_acc: 0.5776\n",
      "Epoch 5/10\n",
      " 91/118 [======================>.......] - ETA: 1:13 - loss: 1.1519 - acc: 0.5935"
     ]
    }
   ],
   "source": [
    "STEP_SIZE_TRAIN=train_generator.n//train_generator.batch_size\n",
    "STEP_SIZE_VALID=valid_generator.n//valid_generator.batch_size\n",
    "#STEP_SIZE_TEST=test_generator.n//test_generator.batch_size\n",
    "new_model.fit_generator(generator=train_generator,\n",
    "                    steps_per_epoch=STEP_SIZE_TRAIN,\n",
    "                    validation_data=valid_generator,\n",
    "                    validation_steps=STEP_SIZE_VALID,\n",
    "                    epochs=10\n",
    ")\n",
    "new_model.evaluate_generator(generator=valid_generator, steps=STEP_SIZE_VALID\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_model.save(\"model.h5\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = history.history['acc']\n",
    "epochs = [x for x in range(10)]\n",
    "print(epochs)\n",
    "plt.plot(epochs,loss)\n",
    "plt.title('Accuracy')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
